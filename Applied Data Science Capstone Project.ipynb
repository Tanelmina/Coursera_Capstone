{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": "import urllib.request, urllib.parse, urllib.error\nimport json\nimport ssl\nimport pandas as pd"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# creating a pandas dataframe\n\ncolumn_names = ['ID', 'English_name','Locality', 'Date', 'Time', 'Latitude', 'Longitude']\ndf = pd.DataFrame(columns=column_names)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#dowloading a data from xeno-canto\n\nctx = ssl.create_default_context()\nctx.check_hostname = False\nctx.verify_mode = ssl.CERT_NONE\n\nxeno_canto__API_v2 = 'https://www.xeno-canto.org/api/2/recordings?query=cnt:united_kingdom'\n\nnumPages = 1\npage = 0\n\nwhile page < numPages:\n    page += 1\n    url = xeno_canto__API_v2+'&page='+str(page)\n    uh = urllib.request.urlopen(url, context=ctx)\n    data = uh.read().decode()\n    if uh.getcode() != 200 :\n            print(\"Error on downloading: \", url, uh.getcode())\n            exit\n    try:\n        js = json.loads(data)\n    except:\n        js = print('=====Error on loading JSON======')\n\n    numPages = js['numPages']\n    page = js['page']\n    numRecordings = js['numRecordings']\n    \n    for item in js['recordings']:\n        df = df.append({'ID' : item['id'],\n                    'English_name' : item['en'],\n                    'Locality': item['loc'],\n                    'Latitude' : item['lat'],\n                    'Longitude' : item['lng'],\n                    'Date' : item['date'],\n                    'Time' : item['time'] , }, ignore_index=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Saving results\n\ndf.to_csv('df.csv', index=False)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Data wrangling"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import numpy as np"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Reading dataframe\n\ndf = pd.read_csv('df.csv')\n\n#Data wrangling\n\nmissing_data = df.isnull()\nfor column in missing_data.columns.values.tolist():\n    print(column)\n    print (missing_data[column].value_counts())\n    print(\"\")    \n\ndf.replace(\"?\", np.nan, inplace = True)\ndf.dropna(subset=['Latitude'], axis=0, inplace=True)\ndf.reset_index(drop=True, inplace=True)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Adding to dataframe column of location county through ArcGIS with geocoder package"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "!conda install -c conda-forge geocoder --yes \nimport geocoder"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "County = []\n\nfor index, row in df.iterrows():\n    try:\n        g = geocoder.arcgis([row['Latitude'], row['Longitude']], method='reverse')\n        County.append(g.json[\"raw\"][\"address\"][\"Subregion\"])\n    except:\n        County.append('Error')\n\ndf['County'] = County"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Saving results\ndf.to_csv('df_arcgis.csv', index=False)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Finding additional information about location county from xeno-canto dataset "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Creating a list of counties from geojson fail (https://data.gov.uk/dataset/d6f97a1a-25dc-485c-9af3-0e5681465d77/counties-and-unitary-authorities-december-2016-full-clipped-boundaries-in-england-and-wales)\n\nwith open('Counties_and_Unitary_Authorities_December_2016_Full_Clipped_Boundaries_in_England_and_Wales.geojson') as f:\n    data = json.load(f)\n  \nCounties = []\nfor item in data['features']:\n    Counties.append(item['properties']['ctyua16nm'])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "County = []\n\nfor index, row in df.iterrows():\n    if row['County'] in Counties:\n        County.append(row['County'])        \n    elif len(row['Locality'].split(', ')) >= 1  and row['Locality'].split(', ')[0] in Counties:\n        County.append(row['Locality'].split(', ')[0])    \n    elif len(row['Locality'].split(', ')) >= 2 and row['Locality'].split(', ')[1] in Counties:        \n        County.append(row['Locality'].split(', ')[1])\n    elif len(row['Locality'].split(', ')) >= 3 and row['Locality'].split(', ')[2] in Counties:\n        County.append(row['Locality'].split(', ')[2])\n    else:\n        County.append(None)  \n\ndf['County'] = County"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Saving results\ndf.to_csv('df_agg.csv', index=False)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Creating map with initial results"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from pandas.io.json import json_normalize\nimport pandas as pd\nimport numpy as np\n!conda install -c conda-forge folium=0.5.0 --yes \nimport folium\nimport json\n!conda install -c conda-forge geocoder --yes \nimport geocoder"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Reading previously saved data\ndf = pd.read_csv('df_agg.csv')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "agg = pd.DataFrame(df['County'].value_counts().to_frame())\nagg.reset_index(drop=False, inplace=True)\nagg.rename(columns={'index' :'County', 'County':'Observations'}, inplace=True)\ndf = agg"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Saving data\ndf.to_csv('counties.csv')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Loading geoJSON data\nwith open('Counties_and_Unitary_Authorities_December_2016_Full_Clipped_Boundaries_in_England_and_Wales.geojson') as f:\n    ew_geo = json.load(f)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "g = geocoder.arcgis('United Kingdom')\new_map = folium.Map(location=[g.lat, g.lng], zoom_start=6, tiles='Mapbox Bright')\n\nthreshold_scale= [0, 100, 200, 300, 400, 500,600,700,int(df['Observations'].max())+1]\n\new_map.choropleth(\n    geo_data=ew_geo,\n    data=df,\n    columns=['County', 'Observations'],\n    key_on='feature.properties.ctyua16nm',\n    fill_color='Blues',\n    fill_opacity=0.7,\n    threshold_scale=threshold_scale,\n    line_opacity=0.2,\n    legend_name='Observations in England and Wales Counties')\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Saving map as html\nm = ew_map\nm.save(\"ew_map2.html\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Generating base dataframe for futher counties clustering"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import pandas as pd\n!conda install -c conda-forge geocoder --yes \nimport geocoder"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "column_names = ['Country', 'County','Latitude', 'Longitude']\new_data = pd.DataFrame(columns=column_names)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Loading data\ndf_agg = pd.read_csv('df_agg.csv')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ew_data['County']=df_agg['County']. unique()\nLatitude=[]\nLongitude=[]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "for c in ew_data.iterrows():\n    try:\n        a= c[1][1]+', UK'\n        g = geocoder.arcgis(a)\n        Latitude.append(g.lat)\n        Longitude.append(g.lng)\n    except:\n        Latitude.append('')\n        Longitude.append('')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ew_data['Latitude']=Latitude\new_data['Longitude']=Longitude"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Saving data\new_data.to_csv('ew_data.csv', index=False)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Preparation of k-mean clustering"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.cluster import KMeans\n!conda install -c conda-forge folium=0.5.0 --yes \nimport folium\n!conda install -c conda-forge geocoder --yes \nimport geocoder\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df = pd.read_csv('df_agg.csv')\ndf.replace(np.nan,'?', inplace = True)\ndf = df[df.County != '?'].reset_index()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Checking how many observations were returned for each county\ndf_sum = df.groupby('County').count()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Let's find out how many unique species can be find from all the returned counties\n\nprint('There are {} uniques species.'.format(len(df['English_name'].unique())))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Analyzing Each County\u00b6\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# one hot encoding\new_onehot = pd.get_dummies(df[['English_name']], prefix=\"\", prefix_sep=\"\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# adding county column back to dataframe\new_onehot['County'] = df['County']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# moving county column to the first column\nfixed_columns = [ew_onehot.columns[-1]] + list(ew_onehot.columns[:-1])\new_onehot = ew_onehot[fixed_columns]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Grouping rows by county and by taking the mean of the frequency of occurrence of each species\n\new_grouped = ew_onehot.groupby('County').mean().reset_index()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Printing each county along with the top 5 most common species\n\nnum_top_species = 5\n\nfor county in ew_grouped['County']:\n    print(\"----\"+county+\"----\")\n    temp = ew_grouped[ew_grouped['County'] == county].T.reset_index()\n    temp.columns = ['species','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_species))\n    print('\\n')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Sorting the species in descending order to use this later on dataframe.\n\ndef return_most_common_species(row, num_top_species):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_species]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Creating the new dataframe and display the top 20 species for each county.\n    \nnum_top_species = 20\nindicators = ['st', 'nd', 'rd']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Creating columns according to number of top species\ncolumns = ['County']\nfor ind in np.arange(num_top_species):\n    try:\n        columns.append('{}{} Most Common Species'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Species'.format(ind+1))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Creating a new dataframe\ncounties_species_sorted = pd.DataFrame(columns=columns)\ncounties_species_sorted['County'] = ew_grouped['County']\n\nfor ind in np.arange(ew_grouped.shape[0]):\n    counties_species_sorted.iloc[ind, 1:] = return_most_common_species(ew_grouped.iloc[ind, :], num_top_species)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Clustering Counties"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Setting number of clusters\nkclusters = 5\new_grouped_clustering = ew_grouped.drop('County', 1)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Running k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(ew_grouped_clustering)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Creating a new dataframe that includes the cluster as well as the top 20 species for each county."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#reading counties coordinates from file\new_data = pd.read_csv('ew_data.csv')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# adding clustering labels\ncounties_species_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\new_merged = ew_data"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# merge ew_merged with counties_species_sorted to add latitude/longitude for each county\new_merged = ew_merged.join(counties_species_sorted.set_index('County'), on='County')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Data cleaning \n\new_merged.dropna(subset=['County'], axis=0, inplace=True)\new_merged.reset_index(drop=True, inplace=True)\new_merged['Cluster Labels']= ew_merged['Cluster Labels'].astype(int)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Visualizing the resulting clusters"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# creating map\ng = geocoder.arcgis('United Kingdom')\nmap_clusters = folium.Map(location=[g.lat, g.lng], zoom_start=6)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# setting color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# adding markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(ew_merged['Latitude'], ew_merged['Longitude'], ew_merged['County'], ew_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)     \n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Saving map as html\nm = map_clusters\nm.save(\"map_clusters.html\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": " Examining Clusters"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "k1 =ew_merged.loc[ew_merged['Cluster Labels'] == 0, ew_merged.columns[[1] + list(range(5, ew_merged.shape[1]))]]\nk2 =ew_merged.loc[ew_merged['Cluster Labels'] == 1, ew_merged.columns[[1] + list(range(5, ew_merged.shape[1]))]]\nk3 =ew_merged.loc[ew_merged['Cluster Labels'] == 2, ew_merged.columns[[1] + list(range(5, ew_merged.shape[1]))]]\nk4 =ew_merged.loc[ew_merged['Cluster Labels'] == 3, ew_merged.columns[[1] + list(range(5, ew_merged.shape[1]))]]\nk5 =ew_merged.loc[ew_merged['Cluster Labels'] == 4, ew_merged.columns[[1] + list(range(5, ew_merged.shape[1]))]]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Saving results\nk1.to_csv('k1.csv')\nk2.to_csv('k2.csv')\nk3.to_csv('k3.csv')\nk4.to_csv('k4.csv')\nk5.to_csv('k5.csv')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Generating figures for raport"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import numpy as np  \nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Generating counties histogram for raport"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df = pd.read_csv('df_agg.csv')\ndf.replace(np.nan,'?', inplace = True)\ndf = df[df.County != '?'].reset_index()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_sum = df.groupby('County').count()\ndf_sum = df_sum.drop(df.columns[[0,2,3,4,5,6,7]], axis=1)\ndf_sum = df_sum.drop(['North Yorkshire'])\ndf_sum.sort_values(['ID'], ascending=False, axis=0, inplace=True)\ndf_sum.rename(columns={'ID':'Observations'}, inplace=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "count, bin_edges = np.histogram(df_sum)\n\nax = df_sum.plot(kind='hist', figsize=(8, 5), xticks=bin_edges)\n\nplt.title('Histogram of Observations per County')\nplt.ylabel('Number of Counties') \nplt.xlabel('Number of Observations') \n\nax.get_legend().remove()\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "plt.savefig('histogram.png')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Generating yearly distribution figure for raport"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_date = df.drop(df.columns[[0,2,3,5,6,7,8]], axis=1)\n\nMonth=[]\n\nfor i, m in df_date.iterrows():\n    if '-' in m[1]:\n        month = m[1].split('-')\n        Month.append(month[1])\n    elif '.' in m[1]:\n        month = m[1].split('.')\n        Month.append(month[1])\n    else:\n        Month.append('')\n        \ndf_date['Month'] = Month\ndf_date['Month'] = df_date['Month'].astype(int)\n\ndf_date = df_date.groupby('Month').count()\n\ndf_date = df_date.drop(df.columns[[1]], axis=1)\ndf_date = df_date.drop([0])\ndf_date.rename(columns={'Date':'Observations'}, inplace=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ax = df_date.plot(kind='bar', figsize=(8, 5))\n\nplt.title('Observations per Month') # add a title to the histogram\nplt.ylabel('Number of Observations') # add y-label\nplt.xlabel('Month') # add x-label\nplt.xticks(rotation= 0 )\n\n\nax.get_legend().remove()\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "plt.savefig('months.png')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Generating daily distribution figure for raport"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_time = df.drop(df.columns[[0,2,3,4,6,7,8]], axis=1)\n\nHour=[]\n\nfor i, m in df_time.iterrows():\n    if ':' in m[1] and len(m[1]) == 5:\n        hour = m[1].split(':')\n        Hour.append(hour[0])\n        #print(hour[0])\n    else:\n        Hour.append('')\n    \n\ndf_time['Hour'] = Hour\ndf_time = df_time.groupby('Hour').count()\n\ndf_time = df_time.drop(df.columns[[1]], axis=1)\ndf_time.rename(columns={'Date':'Observations'}, inplace=True)\ndf_time = df_time.drop([''])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ax = df_time.plot(kind='bar', figsize=(8, 5))\n\nplt.title('Observations per Hour') # add a title to the histogram\nplt.ylabel('Number of Observations') # add y-label\nplt.xlabel('Hour') # add x-label\nplt.xticks(rotation= 0 )\n\nax.get_legend().remove()\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "plt.savefig('hour.png')"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}